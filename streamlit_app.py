# streamlit_app.py
import os
import random
from datetime import datetime, date, time, timedelta, timezone
from typing import Optional
from io import BytesIO
import zipfile

import streamlit as st
import pandas as pd
import altair as alt

# ====== –†–ï–ñ–ò–ú –î–ï–ú–û –î–ê–ù–ù–´–• (–ù–ï –í–õ–ò–Ø–ï–¢ –ù–ê –ê–í–¢–û–†–ò–ó–ê–¶–ò–Æ) ======
FORCE_DEMO_DATA = True  # ‚Üê –ø–æ—Å—Ç–∞–≤—å—Ç–µ False, —á—Ç–æ–±—ã —á–∏—Ç–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î

# ====== –ë–ê–ó–û–í–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ======
st.set_page_config(
    page_title="–°–∏—Å—Ç–µ–º–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏ —É—á—ë—Ç–∞ –∫–∞—Ä—Ç–æ—Ñ–µ–ª—è",
    page_icon="ü•î",
    layout="wide",
)

# ====== –ö–õ–Æ–ß–ò (—á–µ—Ä–µ–∑ .streamlit/secrets.toml –∏–ª–∏ env) ======
SUPABASE_URL = st.secrets.get("SUPABASE_URL", os.getenv("SUPABASE_URL"))
SUPABASE_ANON_KEY = st.secrets.get("SUPABASE_ANON_KEY", os.getenv("SUPABASE_ANON_KEY"))

USE_SUPABASE = bool(SUPABASE_URL and SUPABASE_ANON_KEY)
_sb = None
if USE_SUPABASE:
    try:
        from supabase import create_client
        _sb = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Supabase: {e}")
        USE_SUPABASE = False

# ====== –û–§–û–†–ú–õ–ï–ù–ò–ï ======
st.markdown(
    """
    <style>
      .block-container { padding-top: 2.25rem; }
      .hdr { display:flex; justify-content:space-between; align-items:center; }
      .hdr h1 { margin:0; font-size:26px; font-weight:800; letter-spacing:.3px; }
      .hdr .sub { opacity:.8 }
      .hdr + .spacer { height: 10px; }
      hr { margin: 10px 0 22px 0; opacity:.25; }
      .stDateInput, .stNumberInput, .stTextInput { margin-bottom: .35rem; }
    </style>
    """,
    unsafe_allow_html=True,
)

def header(sub: str | None = None):
    st.markdown(
        f"<div class='hdr'><h1>–°–∏—Å—Ç–µ–º–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏ —É—á—ë—Ç–∞ –∫–∞—Ä—Ç–æ—Ñ–µ–ª—è</h1>{f'<div class=\"sub\">{sub}</div>' if sub else ''}</div>",
        unsafe_allow_html=True
    )
    st.markdown('<div class="spacer"></div>', unsafe_allow_html=True)
    st.markdown("<hr/>", unsafe_allow_html=True)

def df_view(df: pd.DataFrame, caption: str = ""):
    if caption:
        st.caption(caption)
    st.dataframe(df, use_container_width=True)

# ====== –°–ï–°–°–ò–Ø/–†–û–£–¢–ï–† ======
if "authed" not in st.session_state:
    st.session_state["authed"] = False
if "route" not in st.session_state:
    st.session_state["route"] = "login"  # 'login' | 'app'
if "day_picker" not in st.session_state:
    st.session_state["day_picker"] = date.today()  # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

def go(page: str):
    st.session_state["route"] = page
    st.rerun()

# ====== –î–ê–¢–´ ======
def _ensure_aware_utc(dt: datetime) -> datetime:
    if dt.tzinfo is None:
        return dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(timezone.utc)

def week_bounds(d: date) -> tuple[date, date]:
    """–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫..–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –¥–ª—è –¥–∞—Ç—ã d."""
    start = d - timedelta(days=d.weekday())
    end = start + timedelta(days=6)
    return start, end

# ====== –ß–¢–ï–ù–ò–ï –î–ê–ù–ù–´–• (–µ—Å–ª–∏ USE_SUPABASE=True) ======
def fetch_events(point: Optional[str], start_dt: datetime, end_dt: datetime) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ts (naive UTC), point, potato_id, width_cm, height_cm."""
    if not USE_SUPABASE:
        return pd.DataFrame(columns=["ts","point","potato_id","width_cm","height_cm"])
    try:
        q = _sb.table("events").select("*").order("ts", desc=False)
        if point:
            q = q.eq("point", point)
        start_iso = _ensure_aware_utc(start_dt).isoformat()
        end_iso   = _ensure_aware_utc(end_dt).isoformat()
        data = q.gte("ts", start_iso).lte("ts", end_iso).execute().data
        df = pd.DataFrame(data) if data else pd.DataFrame(columns=["ts","point","potato_id","width_cm","height_cm"])
        if "ts" in df.columns:
            df["ts"] = pd.to_datetime(df["ts"], utc=True, errors="coerce")\
                          .dt.tz_convert("UTC").dt.tz_localize(None)
        for col in ("width_cm","height_cm"):
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        return df
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Supabase: {e}")
        return pd.DataFrame(columns=["ts","point","potato_id","width_cm","height_cm"])

def hour_counts(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "ts" not in df.columns:
        return pd.DataFrame({"hour":[], "count":[]})
    return (
        df.assign(hour=pd.to_datetime(df["ts"]).dt.floor("h"))
          .groupby("hour", as_index=False)
          .agg(count=("potato_id", "nunique"))
    )

def day_counts(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "ts" not in df.columns:
        return pd.DataFrame({"day":[], "count":[]})
    return (
        df.assign(day=pd.to_datetime(df["ts"]).dt.floor("D"))
          .groupby("day", as_index=False)
          .agg(count=("potato_id", "nunique"))
    )

# ====== –ö–ê–¢–ï–ì–û–†–ò–ò ======
CATEGORIES = ["<30", "30‚Äì40", "40‚Äì50", "50‚Äì60", ">60"]

def bins_table(dfA: pd.DataFrame, dfB: pd.DataFrame) -> pd.DataFrame:
    """A=–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ, B=–°–æ–±—Ä–∞–Ω–æ. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
    def count_bins(df: pd.DataFrame) -> pd.Series:
        if df.empty or ("width_cm" not in df.columns):
            return pd.Series({c: 0 for c in CATEGORIES})
        bins = [0,30,40,50,60,10_000]
        labels = CATEGORIES
        cut = pd.cut(
            df["width_cm"].fillna(-1),
            bins=bins, labels=labels, right=False, include_lowest=True
        )
        vc = cut.value_counts().reindex(labels).fillna(0).astype(int)
        return vc

    A = count_bins(dfA)   # –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)
    B = count_bins(dfB)   # –°–æ–±—Ä–∞–Ω–æ   (B)
    losses = (A - B).clip(lower=0)
    loss_pct = pd.Series({c: (0.0 if A[c]==0 else round(losses[c]/A[c]*100, 1)) for c in CATEGORIES})

    return pd.DataFrame({
        "–ö–∞—Ç–µ–≥–æ—Ä–∏—è":    CATEGORIES,
        "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ":   [int(A[c])      for c in CATEGORIES],
        "–ü–æ—Ç–µ—Ä–∏ (—à—Ç)":  [int(losses[c]) for c in CATEGORIES],
        "–°–æ–±—Ä–∞–Ω–æ":      [int(B[c])      for c in CATEGORIES],
        "% –ø–æ—Ç–µ—Ä–∏":     [float(loss_pct[c]) for c in CATEGORIES],
    })

# ====== –î–ï–ú–û-–î–ê–ù–ù–´–ï ======
def demo_generate(day: date, base: int = 620, jitter: int = 90, seed: int = 42):
    rng = random.Random(seed + int(day.strftime("%Y%m%d")))
    hours = [datetime.combine(day, time(h,0)) for h in range(24)]
    rowsA, rowsB = [], []
    pid = 1
    for ts in hours:
        countA = max(0, int(rng.gauss(base, jitter)))
        countB = int(countA * rng.uniform(0.70, 0.85))
        for _ in range(countA):
            width = max(25.0, min(75.0, rng.gauss(52.0, 8.5)))
            rowsA.append({"ts": ts + timedelta(minutes=rng.randint(0,59)), "point":"A", "potato_id":pid, "width_cm":width, "height_cm":width*0.7})
            pid += 1
        for _ in range(countB):
            width = max(25.0, min(75.0, rng.gauss(53.0, 7.5)))
            rowsB.append({"ts": ts + timedelta(minutes=rng.randint(0,59)), "point":"B", "potato_id":pid, "width_cm":width, "height_cm":width*0.7})
            pid += 1
    return pd.DataFrame(rowsA), pd.DataFrame(rowsB)

def demo_generate_range(ref_day: date, days: int = 31):
    dfAs, dfBs = [], []
    for d in range(days-1, -1, -1):
        day_i = ref_day - timedelta(days=d)
        a, b = demo_generate(day_i)
        dfAs.append(a); dfBs.append(b)
    return pd.concat(dfAs, ignore_index=True), pd.concat(dfBs, ignore_index=True)

def demo_generate_week(week_start: date, week_end: date):
    dfAs, dfBs = [], []
    cur = week_start
    while cur <= week_end:
        a, b = demo_generate(cur)
        dfAs.append(a); dfBs.append(b)
        cur += timedelta(days=1)
    return pd.concat(dfAs, ignore_index=True), pd.concat(dfBs, ignore_index=True)

# ====== –õ–û–ì–ò–ù (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π; –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ USE_SUPABASE=True) ======
def page_login():
    st.subheader("–í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
    with st.form("login_form", clear_on_submit=False):
        email = st.text_input("E-mail", placeholder="you@company.com")
        password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", placeholder="‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢")
        submitted = st.form_submit_button("–í–æ–π—Ç–∏")
    if submitted:
        ok = True
        if USE_SUPABASE:
            try:
                resp = _sb.auth.sign_in_with_password({"email": email, "password": password})
                ok = bool(getattr(resp, "user", None))
                if not ok:
                    st.error("–ù–µ–≤–µ—Ä–Ω–∞—è –ø–æ—á—Ç–∞ –∏–ª–∏ –ø–∞—Ä–æ–ª—å.")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
                ok = False
        if ok:
            st.session_state["authed"] = True
            st.session_state["route"] = "app"
            st.rerun()
    st.caption("–î–æ—Å—Ç—É–ø –≤—ã–¥–∞—ë—Ç—Å—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º–∏.")

# ====== –£–¢–ò–õ–ò–¢–ê: Excel-–≤—ã–≥—Ä—É–∑–∫–∞ —Å –∞–≤—Ç–æ-–ø–æ–¥–±–æ—Ä–æ–º —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫ ======
def make_excel_bytes(hour_df: pd.DataFrame, bins_df: pd.DataFrame) -> tuple[bytes, str, str]:
    try:
        import xlsxwriter  # noqa: F401
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter", datetime_format="yyyy-mm-dd hh:mm") as writer:
            hour_df.to_excel(writer, index=False, sheet_name="–ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º")
            bins_df.to_excel(writer, index=False, sheet_name="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
            wb = writer.book
            ws_hours = writer.sheets["–ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º"]
            ws_bins  = writer.sheets["–ö–∞—Ç–µ–≥–æ—Ä–∏–∏"]
            dt_fmt = wb.add_format({"num_format": "yyyy-mm-dd hh:mm"})
            for col_idx, col_name in enumerate(hour_df.columns):
                col_data = hour_df[col_name]
                if pd.api.types.is_datetime64_any_dtype(col_data):
                    width = max(len(str(col_name)), 16) + 2
                    ws_hours.set_column(col_idx, col_idx, width, dt_fmt)
                else:
                    max_len = max(len(str(col_name)), int(col_data.astype(str).map(len).max() or 0))
                    ws_hours.set_column(col_idx, col_idx, max_len + 2)
            for col_idx, col_name in enumerate(bins_df.columns):
                col_data = bins_df[col_name]
                max_len = max(len(str(col_name)), int(col_data.astype(str).map(len).max() or 0))
                ws_bins.set_column(col_idx, col_idx, max_len + 2)
        return buf.getvalue(), "xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    except Exception:
        pass

    try:
        import openpyxl  # noqa: F401
        from openpyxl.utils import get_column_letter
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl", datetime_format="yyyy-mm-dd hh:mm") as writer:
            hour_df.to_excel(writer, index=False, sheet_name="–ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º")
            bins_df.to_excel(writer, index=False, sheet_name="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
            ws_hours = writer.sheets["–ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º"]
            ws_bins  = writer.sheets["–ö–∞—Ç–µ–≥–æ—Ä–∏–∏"]
            def autofit(ws, df):
                for idx, col_name in enumerate(df.columns, start=1):
                    col_letter = get_column_letter(idx)
                    col_series = df[col_name]
                    if pd.api.types.is_datetime64_any_dtype(col_series):
                        width = max(len(str(col_name)), 16) + 2
                        ws.column_dimensions[col_letter].width = width
                        for row in range(2, len(col_series) + 2):
                            ws[f"{col_letter}{row}"].number_format = "yyyy-mm-dd hh:mm"
                    else:
                        max_len = max(len(str(col_name)), int(col_series.astype(str).map(len).max() or 0))
                        ws.column_dimensions[col_letter].width = max_len + 2
            autofit(ws_hours, hour_df); autofit(ws_bins, bins_df)
        return buf.getvalue(), "xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    except Exception:
        pass

    buf = BytesIO()
    with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("–ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º.csv", hour_df.to_csv(index=False))
        zf.writestr("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏.csv",    bins_df.to_csv(index=False))
    return buf.getvalue(), "zip", "application/zip"

# ====== –ß–ê–†–¢ –ü–û –ß–ê–°–ê–ú (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ======
def render_hour_chart_grouped(dfA: pd.DataFrame, dfB: pd.DataFrame):
    ha = hour_counts(dfA).rename(columns={"count": "initial"})   # A = –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ
    hb = hour_counts(dfB).rename(columns={"count": "collected"}) # B = –ò—Ç–æ–≥–æ (–ë)
    merged = pd.merge(ha, hb, on="hour", how="outer").sort_values("hour")
    if merged.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        return pd.DataFrame()

    merged[["initial", "collected"]] = merged[["initial", "collected"]].fillna(0).astype(int)
    merged["diff"] = (merged["initial"] - merged["collected"]).clip(lower=0)

    long_df = pd.concat([
        merged[["hour", "collected"]].rename(columns={"collected": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).assign(–°–µ–≥–º–µ–Ω—Ç="–ò—Ç–æ–≥–æ (B)"),
        merged[["hour", "diff"]].rename(columns={"diff": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).assign(–°–µ–≥–º–µ–Ω—Ç="–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)"),
    ], ignore_index=True)

    x_axis = alt.X(
        "hour:T",
        title="–î–∞—Ç–∞ –∏ —á–∞—Å",
        axis=alt.Axis(titlePadding=24, labelOverlap=True, labelFlush=True, titleAnchor="start"),
    )

    chart = (
        alt.Chart(long_df)
        .mark_bar()
        .encode(
            x=x_axis,
            y=alt.Y("–ó–Ω–∞—á–µ–Ω–∏–µ:Q", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", stack="zero"),
            color=alt.Color("–°–µ–≥–º–µ–Ω—Ç:N", title="", scale=alt.Scale(domain=["–ò—Ç–æ–≥–æ (B)", "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)"])),
            tooltip=[alt.Tooltip("hour:T", title="–ß–∞—Å"), alt.Tooltip("–°–µ–≥–º–µ–Ω—Ç:N"), alt.Tooltip("–ó–Ω–∞—á–µ–Ω–∏–µ:Q", title="–í —Å–µ–≥–º–µ–Ω—Ç–µ")],
        )
        .properties(height=320, padding={"top": 10, "right": 12, "bottom": 44, "left": 8})
        .configure_axis(labelFontSize=12, titleFontSize=12)
    )

    st.altair_chart(chart, use_container_width=True)
    st.markdown("<div style='height:12px'></div>", unsafe_allow_html=True)
    return merged

# ====== –ß–ê–†–¢ –ü–û –ù–ï–î–ï–õ–Ø–ú (—Å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π –∏ —Ä—É—Å—Å–∫–∏–º–∏ –¥–Ω—è–º–∏) ======
RU_DOW = ["–ü–Ω", "–í—Ç", "–°—Ä", "–ß—Ç", "–ü—Ç", "–°–±", "–í—Å"]

def _shift_week(delta_days: int):
    # callback –¥–ª—è –∫–Ω–æ–ø–æ–∫ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    st.session_state["day_picker"] = st.session_state["day_picker"] + timedelta(days=delta_days)

def render_week_chart_grouped(dfA: pd.DataFrame, dfB: pd.DataFrame, week_start: date, week_end: date):
    # –ü–∞–Ω–µ–ª—å –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –Ω–µ–¥–µ–ª—è–º–∏ (–∫–Ω–æ–ø–∫–∏ "<" –∏ ">")
    nav_left, nav_center, nav_right = st.columns([1, 2, 1])
    with nav_left:
        st.button("<", key="week_prev_btn", on_click=_shift_week, args=(-7,))
    with nav_center:
        st.markdown(
            f"<div style='text-align:center; font-weight:600;'>–ù–µ–¥–µ–ª—è: {week_start.strftime('%d.%m')} ‚Äî {week_end.strftime('%d.%m')}</div>",
            unsafe_allow_html=True
        )
    with nav_right:
        st.button(">", key="week_next_btn", on_click=_shift_week, args=(7,))

    if dfA.empty and dfB.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —ç—Ç—É –Ω–µ–¥–µ–ª—é.")
        return pd.DataFrame()

    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ (0=–ü–Ω..6=–í—Å)
    da = day_counts(dfA).rename(columns={"count": "initial"})
    db = day_counts(dfB).rename(columns={"count": "collected"})

    # –ì–æ—Ç–æ–≤–∏–º –ø–æ–ª–Ω—ã–π –∫–∞—Ä–∫–∞—Å –Ω–µ–¥–µ–ª–∏, —á—Ç–æ–±—ã –≤—Å–µ–≥–¥–∞ –±—ã–ª–æ 7 —Å—Ç–æ–ª–±–∏–∫–æ–≤
    base = pd.DataFrame({
        "day": [pd.Timestamp(week_start + timedelta(days=i)) for i in range(7)],
        "dow": list(range(7)),
    })

    da["day"] = pd.to_datetime(da["day"]).dt.floor("D")
    db["day"] = pd.to_datetime(db["day"]).dt.floor("D")

    merged = base.merge(da, on="day", how="left").merge(db, on="day", how="left", suffixes=("", "_b"))
    merged[["initial", "collected"]] = merged[["initial", "collected"]].fillna(0).astype(int)
    merged["diff"] = (merged["initial"] - merged["collected"]).clip(lower=0)
    merged["–î–µ–Ω—å"] = merged["dow"].map(lambda i: RU_DOW[i])
    merged["–î–∞—Ç–∞"] = merged["day"].dt.strftime("%Y-%m-%d")

    long_df = pd.concat([
        merged[["–î–µ–Ω—å", "–î–∞—Ç–∞", "collected"]].rename(columns={"collected": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).assign(–°–µ–≥–º–µ–Ω—Ç="–ò—Ç–æ–≥–æ (B)"),
        merged[["–î–µ–Ω—å", "–î–∞—Ç–∞", "diff"]].rename(columns={"diff": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).assign(–°–µ–≥–º–µ–Ω—Ç="–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)"),
    ], ignore_index=True)

    chart = (
        alt.Chart(long_df)
        .mark_bar()
        .encode(
            x=alt.X("–î–µ–Ω—å:N", title="–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏", sort=RU_DOW),
            y=alt.Y("–ó–Ω–∞—á–µ–Ω–∏–µ:Q", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", stack="zero"),
            color=alt.Color("–°–µ–≥–º–µ–Ω—Ç:N", title="", scale=alt.Scale(domain=["–ò—Ç–æ–≥–æ (B)", "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)"])),
            tooltip=[alt.Tooltip("–î–µ–Ω—å:N"), alt.Tooltip("–î–∞—Ç–∞:N"), alt.Tooltip("–°–µ–≥–º–µ–Ω—Ç:N"), alt.Tooltip("–ó–Ω–∞—á–µ–Ω–∏–µ:Q", title="–í —Å–µ–≥–º–µ–Ω—Ç–µ")],
        )
        .properties(height=320, padding={"top": 10, "right": 12, "bottom": 44, "left": 8})
        .configure_axis(labelFontSize=12, titleFontSize=12)
    )
    st.altair_chart(chart, use_container_width=True)
    return merged

# ====== –¢–û–ü-10 –î–ù–ï–ô –£–†–û–ñ–ê–Ø ======
def render_top10_days(dfA_31: pd.DataFrame, dfB_31: pd.DataFrame):
    dB = day_counts(dfB_31)
    if dB.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–ø-10 –¥–Ω–µ–π.")
        return

    top = dB.nlargest(10, "count").sort_values("count", ascending=True)
    top["–î–∞—Ç–∞"] = pd.to_datetime(top["day"]).dt.strftime("%Y-%m-%d")

    chart = (
        alt.Chart(top)
        .mark_bar()
        .encode(
            x=alt.X("count:Q", title="–°–æ–±—Ä–∞–Ω–æ (—à—Ç)"),
            y=alt.Y("–î–∞—Ç–∞:N", sort=None, title=""),
            tooltip=[alt.Tooltip("–î–∞—Ç–∞:N"), alt.Tooltip("count:Q", title="–°–æ–±—Ä–∞–Ω–æ (—à—Ç)")],
        )
        .properties(height=28 * len(top) + 20)
    )
    st.altair_chart(chart, use_container_width=True)

# ====== –ö–ê–õ–¨–ö–£–õ–Ø–¢–û–† –ö–ê–ü–ò–¢–ê–õ–ê ======
DEFAULT_WEIGHT_G = {"<30": 20.0, "30‚Äì40": 48.0, "40‚Äì50": 83.0, "50‚Äì60": 130.0, ">60": 205.0}
DEFAULT_PRICE_KG = {"<30": 0.0,  "30‚Äì40": 0.0,  "40‚Äì50": 0.0,  "50‚Äì60": 0.0,  ">60": 0.0}

def capital_calculator(bins_df: pd.DataFrame):
    st.markdown("### –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∫–∞–ø–∏—Ç–∞–ª–∞")

    counts = dict(zip(bins_df["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"], bins_df["–°–æ–±—Ä–∞–Ω–æ"]))

    col_w = st.columns(5)
    col_p = st.columns(5)
    weights_g = {}
    prices_kg = {}

    for i, cat in enumerate(CATEGORIES):
        with col_w[i]:
            weights_g[cat] = st.number_input(
                f"–í–µ—Å ({cat}), –≥/—à—Ç",
                min_value=0.0,
                step=10.0,
                value=float(DEFAULT_WEIGHT_G.get(cat, 0.0)),
                format="%.2f",
                key=f"calc_w_{cat}",
            )
        with col_p[i]:
            prices_kg[cat] = st.number_input(
                f"–¶–µ–Ω–∞ ({cat}), —Ç–≥/–∫–≥",
                min_value=0.0,
                step=10.0,
                value=float(DEFAULT_PRICE_KG.get(cat, 0.0)),
                format="%.2f",
                key=f"calc_p_{cat}",
            )

    kg_totals = {cat: (counts.get(cat, 0) * weights_g.get(cat, 0.0)) / 1000.0 for cat in CATEGORIES}
    subtotals = {cat: kg_totals[cat] * prices_kg.get(cat, 0.0) for cat in CATEGORIES}
    total_sum = round(sum(subtotals.values()), 2)

    calc_df = pd.DataFrame({
        "–ö–∞—Ç–µ–≥–æ—Ä–∏—è":        CATEGORIES,
        "–°–æ–±—Ä–∞–Ω–æ (—à—Ç)":     [int(counts.get(c, 0)) for c in CATEGORIES],
        "–í–µ—Å, –≥/—à—Ç":        [weights_g[c] for c in CATEGORIES],
        "–ò—Ç–æ–≥–æ, –∫–≥":        [round(kg_totals[c], 3) for c in CATEGORIES],
        "–¶–µ–Ω–∞, —Ç–≥/–∫–≥":      [prices_kg[c] for c in CATEGORIES],
        "–°—É–º–º–∞, —Ç–≥":        [round(subtotals[c], 2) for c in CATEGORIES],
    })
    df_view(calc_df)
    st.subheader(f"–ò—Ç–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª: **{total_sum:,.2f} —Ç–≥**".replace(",", " "))

# ====== –í–ï–°–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê ======
def render_weight_table(day: date):
    rng = random.Random(1000 + int(day.strftime("%Y%m%d")))
    hours = [10, 12, 14, 16]
    weights = [round(rng.uniform(0.12, 0.22), 3) for _ in hours]  # —Ç–æ–Ω–Ω—ã
    rows = []
    for h, w in zip(hours, weights):
        ts = datetime.combine(day, time(h, 0))
        rows.append({"–î–∞—Ç–∞ –∏ —á–∞—Å": ts.strftime("%Y-%m-%d %H:%M"), "–í–µ—Å, —Ç": w})
    df = pd.DataFrame(rows)
    st.markdown("### –í–µ—Å–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    df_view(df)

# ====== –ì–õ–ê–í–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ======
def page_dashboard_online():
    header()

    c_top1, c_top2, c_top3 = st.columns([1.3,1,1])
    with c_top1:
        st.date_input("–î–∞—Ç–∞", key="day_picker")  # –±–µ–∑ value=..., –∏—Å–ø–æ–ª—å–∑—É–µ–º session_state
    with c_top2:
        st.empty()
    with c_top3:
        top_right = st.container()
        if st.button("–í—ã–π—Ç–∏"):
            st.session_state["authed"] = False
            go("login")

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    # --- –î–∞–Ω–Ω—ã–µ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–µ–Ω—å
    day = st.session_state["day_picker"]
    start = datetime.combine(day, time.min).replace(tzinfo=timezone.utc)
    end   = datetime.combine(day, time.max).replace(tzinfo=timezone.utc)

    if FORCE_DEMO_DATA:
        dfA, dfB = demo_generate(day)
    else:
        dfA = fetch_events("A", start, end)
        dfB = fetch_events("B", start, end)
        if dfA.empty and dfB.empty:
            dfA, dfB = demo_generate(day)

    # --- –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –¥–µ–Ω—å
    total_initial = dfA["potato_id"].nunique() if not dfA.empty else 0
    total_collected = dfB["potato_id"].nunique() if not dfB.empty else 0
    total_losses = max(0, total_initial - total_collected)

    m1, m2, m3 = st.columns(3)
    m1.metric("–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (—à—Ç)", value=f"{total_initial}")
    m2.metric("–ü–æ—Ç–µ—Ä–∏ (—à—Ç)", value=f"{total_losses}")
    m3.metric("–°–æ–±—Ä–∞–Ω–æ (—à—Ç)", value=f"{total_collected}")

    # --- –ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º (–∫–∞–∫ –±—ã–ª)
    st.markdown("### –ü–æ—Ç–æ–∫ –ø–æ —á–∞—Å–∞–º")
    merged_hours = render_hour_chart_grouped(dfA, dfB)

    # --- Excel (—á–∞—Å–∞ + –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    ha = hour_counts(dfA).rename(columns={"count": "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ (A)"})
    hb = hour_counts(dfB).rename(columns={"count": "–ò—Ç–æ–≥–æ (B)"})
    hour_export = pd.merge(ha, hb, on="hour", how="outer").sort_values("hour")
    hour_export = hour_export.fillna(0).rename(columns={"hour": "–î–∞—Ç–∞ –∏ —á–∞—Å"})
    bins_df = bins_table(dfA, dfB)

    file_bytes, ext, mime = make_excel_bytes(hour_export, bins_df)
    with top_right:
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç" + (" (Excel)" if ext == "xlsx" else " (ZIP/CSV)"),
            data=file_bytes,
            file_name=f"potato_report_{day.isoformat()}." + ext,
            mime=mime,
            use_container_width=True
        )

    # --- –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 31 –¥–µ–Ω—å (–¥–ª—è —Ç–æ–ø-10)
    start_31 = datetime.combine(day - timedelta(days=30), time.min).replace(tzinfo=timezone.utc)
    end_31   = datetime.combine(day, time.max).replace(tzinfo=timezone.utc)

    if FORCE_DEMO_DATA:
        dfA_31, dfB_31 = demo_generate_range(day, days=31)
    else:
        dfA_31 = fetch_events("A", start_31, end_31)
        dfB_31 = fetch_events("B", start_31, end_31)
        if dfA_31.empty and dfB_31.empty:
            dfA_31, dfB_31 = demo_generate_range(day, days=31)

    # --- –ü–æ—Ç–æ–∫ –ø–æ –Ω–µ–¥–µ–ª—è–º (—Å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π –∏ —Ä—É—Å—Å–∫–∏–º–∏ –¥–Ω—è–º–∏)
    st.markdown("### –ü–æ—Ç–æ–∫ –ø–æ –Ω–µ–¥–µ–ª—è–º")
    week_start, week_end = week_bounds(day)
    if FORCE_DEMO_DATA:
        wA, wB = demo_generate_week(week_start, week_end)
    else:
        ws_dt = datetime.combine(week_start, time.min).replace(tzinfo=timezone.utc)
        we_dt = datetime.combine(week_end,   time.max).replace(tzinfo=timezone.utc)
        wA = fetch_events("A", ws_dt, we_dt)
        wB = fetch_events("B", ws_dt, we_dt)
        if wA.empty and wB.empty:
            wA, wB = demo_generate_week(week_start, week_end)

    render_week_chart_grouped(wA, wB, week_start, week_end)

    # --- –¢–æ–ø-10 –¥–Ω–µ–π —É—Ä–æ–∂–∞—è
    st.markdown("### –¢–æ–ø-10 –¥–Ω–µ–π —É—Ä–æ–∂–∞—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 31 –¥–µ–Ω—å")
    render_top10_days(dfA_31, dfB_31)

    # --- –¢–∞–±–ª–∏—Ü–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)
    st.markdown("### –¢–∞–±–ª–∏—Ü–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É")
    df_view(bins_df[["–ö–∞—Ç–µ–≥–æ—Ä–∏—è","–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ","–ü–æ—Ç–µ—Ä–∏ (—à—Ç)","–°–æ–±—Ä–∞–Ω–æ","% –ø–æ—Ç–µ—Ä–∏"]])

    # --- –í–µ—Å–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–¥–µ–º–æ 4 —Å—Ç—Ä–æ–∫–∏)
    render_weight_table(day)

    # --- –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä
    capital_calculator(bins_df)

# ====== APP (–±–µ–∑ –≤–∫–ª–∞–¥–æ–∫) ======
def page_app():
    page_dashboard_online()

# ====== MAIN ======
def main():
    if not USE_SUPABASE:
        st.session_state["authed"] = True
        st.session_state["route"] = "app"

    route = st.session_state.get("route", "login")
    authed = st.session_state.get("authed", False)

    if route == "login" and USE_SUPABASE and not authed:
        header("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
        page_login()
        return

    page_app()

if __name__ == "__main__":
    main()
